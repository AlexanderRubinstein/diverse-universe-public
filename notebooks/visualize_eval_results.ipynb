{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from stuned.utility.utils import (\n",
    "    get_project_root_path,\n",
    "    log_or_print\n",
    ")\n",
    "\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.dirname(os.path.abspath(''))\n",
    ")\n",
    "from diverse_universe.local_datasets.imagenet_c import (\n",
    "    IN_C_DATALOADERS_NAMES,\n",
    ")\n",
    "sys.path.pop(0)\n",
    "\n",
    "\n",
    "DEFAULT_ROUND = 9\n",
    "HYPERPARAM_PREFIX = \"__hyperparam__\"\n",
    "PICKLES_PATH = os.path.join(get_project_root_path(), \"result_pickles\")\n",
    "ALL_CORRUPTION_NAMES = list(IN_C_DATALOADERS_NAMES.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_table_from_cross_dict(\n",
    "    path_to_dict,\n",
    "    value_name,\n",
    "    round_to=None,\n",
    "    to_show=True,\n",
    "    multiplier=1,\n",
    "    merge_map=None,\n",
    "    logger=None,\n",
    "    model_names=None\n",
    "):\n",
    "    def init_with_dicts(d, key):\n",
    "        if key not in d:\n",
    "            d[key] = {}\n",
    "\n",
    "    def round_string(value, round_to=round_to, multiplier=multiplier, sep=\"+-\"):\n",
    "        mean, std = extract_mean_std(value, sep=sep)\n",
    "        mean *= multiplier\n",
    "        std *= multiplier\n",
    "        return make_mean_std_str(mean, std, round_to, sep=sep)\n",
    "\n",
    "    def as_sorted(iterable):\n",
    "        return sorted(list(iterable), key=lambda x: x[0])\n",
    "\n",
    "    def merge_dicts(dicts):\n",
    "        res = {}\n",
    "        for d in dicts:\n",
    "            for key in d:\n",
    "                if key not in res:\n",
    "                    res[key] = d[key]\n",
    "                else:\n",
    "                    assert len(\n",
    "                        set(d[key].keys()).intersection(set(res[key].keys()))\n",
    "                    ) == 0\n",
    "                    res[key] |= d[key]\n",
    "\n",
    "        return res\n",
    "\n",
    "    if isinstance(path_to_dict, list):\n",
    "        cross_dict = merge_dicts([torch.load(path) for path in path_to_dict])\n",
    "    else:\n",
    "        cross_dict = torch.load(path_to_dict)\n",
    "\n",
    "    res = {}\n",
    "    hyperparams = {}\n",
    "    # cross_dict: (i, j, k) model i -> dataset j -> stats k\n",
    "    for model_name, model_dict in as_sorted(cross_dict.items()):\n",
    "\n",
    "        init_with_dicts(res, model_name)\n",
    "        init_with_dicts(hyperparams, model_name)\n",
    "\n",
    "        if model_names is not None:\n",
    "            assert isinstance(model_names, list)\n",
    "            model_names.append(model_name)\n",
    "\n",
    "        for dataset_name, stats in as_sorted(model_dict.items()):\n",
    "\n",
    "            if HYPERPARAM_PREFIX in dataset_name:\n",
    "                split = dataset_name.split(HYPERPARAM_PREFIX)\n",
    "                assert len(split) == 2\n",
    "                hyperparams[model_name][split[1]] = stats\n",
    "                continue\n",
    "\n",
    "            assert isinstance(stats, dict)\n",
    "            if value_name not in stats:\n",
    "                log_or_print(\n",
    "                    f\"For {model_name} on {dataset_name} value {value_name} \"\n",
    "                    f\"not found among {stats.keys()}\",\n",
    "                    logger,\n",
    "                    auto_newline=True\n",
    "                )\n",
    "            value = stats.get(value_name)\n",
    "\n",
    "            if value is not None and round_to is not None:\n",
    "                value = round_string(value)\n",
    "\n",
    "            res[model_name][dataset_name] = value\n",
    "\n",
    "        if merge_map is not None:\n",
    "            # merge_map: merged_name -> [<names of datasets to merge>]\n",
    "            for merged_dataset in merge_map.keys():\n",
    "                datasets_to_merge_names = merge_map[merged_dataset]\n",
    "                datasets_to_merge_values = []\n",
    "                for dataset_to_merge in datasets_to_merge_names:\n",
    "                    datasets_to_merge_values.append(\n",
    "                        res[model_name].pop(dataset_to_merge)\n",
    "                    )\n",
    "\n",
    "                res[model_name][merged_dataset] = merge_mean_std(\n",
    "                   datasets_to_merge_values,\n",
    "                   round_to\n",
    "                )\n",
    "\n",
    "    df = pd.DataFrame.from_dict(res, orient='index')\n",
    "    hyperparams = pd.DataFrame.from_dict(hyperparams, orient='index')\n",
    "\n",
    "    if to_show:\n",
    "        log_or_print(\n",
    "            f\"Table for {value_name}\",\n",
    "            logger,\n",
    "            auto_newline=True\n",
    "        )\n",
    "        display(df)\n",
    "    return df, hyperparams\n",
    "\n",
    "\n",
    "def extract_mean_std(value, sep=\"+-\"):\n",
    "    if value is None:\n",
    "        return None, None\n",
    "    mean, std = map(float, value.split(sep))\n",
    "    return mean, std\n",
    "\n",
    "def make_mean_std_str(mean, std, round_to, sep=\"+-\"):\n",
    "    if mean is None or std is None:\n",
    "        assert std is None and mean is None\n",
    "        return None\n",
    "\n",
    "    return f\"{round(mean, round_to)} {sep} {round(std, round_to)}\"\n",
    "\n",
    "\n",
    "def merge_mean_std(values, round_to, sep=\"+-\"):\n",
    "\n",
    "    means, stds = [], []\n",
    "    for value in values:\n",
    "        mean, std = extract_mean_std(value, sep=sep)\n",
    "        if mean is not None:\n",
    "            means.append(mean)\n",
    "        if std is not None:\n",
    "            stds.append(std)\n",
    "\n",
    "    res_mean, res_std = None, None\n",
    "    if len(means) > 0:\n",
    "        res_mean = np.array(means).mean()\n",
    "    if len(stds) > 0:\n",
    "        res_std = np.sqrt((np.array(stds) ** 2).sum())\n",
    "    return make_mean_std_str(res_mean, res_std, round_to, sep=sep)\n",
    "\n",
    "\n",
    "def get_long_table(\n",
    "    pths,\n",
    "    metric_names,\n",
    "    axis,\n",
    "    row_names,\n",
    "    col_names,\n",
    "    format_func,\n",
    "    group_by_columns=False,\n",
    "    merge_map=None\n",
    "):\n",
    "\n",
    "    dfs = []\n",
    "    hyperparams = None\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "\n",
    "        if row_names is None:\n",
    "            extracted_model_names = []\n",
    "        else:\n",
    "            extracted_model_names = None\n",
    "\n",
    "        if isinstance(metric_name, tuple):\n",
    "            assert len(metric_name) == 2\n",
    "            multiplier = metric_name[1]\n",
    "            metric_name = metric_name[0]\n",
    "        else:\n",
    "            multiplier = 1\n",
    "\n",
    "        df, hyperparams_df = plot_table_from_cross_dict(\n",
    "            pths,\n",
    "            metric_name,\n",
    "            round_to=DEFAULT_ROUND,\n",
    "            to_show=False,\n",
    "            multiplier=multiplier,\n",
    "            merge_map=merge_map,\n",
    "            model_names=extracted_model_names\n",
    "        )\n",
    "        if hyperparams is None:\n",
    "            hyperparams = hyperparams_df\n",
    "        else:\n",
    "            assert hyperparams.equals(hyperparams_df)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "        if extracted_model_names is not None:\n",
    "            row_names = extracted_model_names\n",
    "\n",
    "    return merge_dfs(\n",
    "        dfs,\n",
    "        axis,\n",
    "        row_names=row_names,\n",
    "        col_names=col_names,\n",
    "        format_func=format_func,\n",
    "        group_by_columns=group_by_columns,\n",
    "        metric_names=metric_names,\n",
    "        just_concat=[hyperparams_df]\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_dfs(\n",
    "    dfs,\n",
    "    axis,\n",
    "    row_names=None,\n",
    "    col_names=None,\n",
    "    format_func=None,\n",
    "    group_by_columns=False,\n",
    "    insert_empty_cols=True,\n",
    "    metric_names=None,\n",
    "    just_concat=[]\n",
    "):\n",
    "\n",
    "    def insert_row_above(df, row_as_list):\n",
    "\n",
    "        df = pd.concat(\n",
    "            [pd.DataFrame([row_as_list], columns=df.columns), df]\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    if metric_names is not None:\n",
    "        assert len(metric_names) == len(dfs)\n",
    "\n",
    "    if group_by_columns:\n",
    "        pre_groupped = {}\n",
    "    else:\n",
    "        pre_groupped = None\n",
    "    for i in range(len(dfs)):\n",
    "        if row_names is not None:\n",
    "            dfs[i] = dfs[i].loc[row_names]\n",
    "        if col_names is not None:\n",
    "            dfs[i] = dfs[i].loc[:, col_names]\n",
    "        if format_func is not None:\n",
    "            dfs[i] = dfs[i].applymap(format_func)\n",
    "\n",
    "        if metric_names is not None:\n",
    "            row_as_list = [metric_names[i]] * len(dfs[i].columns)\n",
    "            dfs[i] = insert_row_above(\n",
    "                dfs[i],\n",
    "                row_as_list\n",
    "            )\n",
    "\n",
    "        if pre_groupped is not None:\n",
    "            for column_name in dfs[i].columns:\n",
    "                if column_name not in pre_groupped:\n",
    "                    pre_groupped[column_name] = []\n",
    "\n",
    "                pre_groupped[column_name].append(\n",
    "                    dfs[i][[column_name]]\n",
    "                )\n",
    "\n",
    "    if pre_groupped is None:\n",
    "        dfs_to_concat = dfs\n",
    "    else:\n",
    "        dfs_to_concat = [\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        single_column\n",
    "                            for single_column\n",
    "                                in pre_groupped_for_column\n",
    "                    ],\n",
    "                    axis=axis\n",
    "                )\n",
    "                        for pre_groupped_for_column\n",
    "                        in pre_groupped.values()\n",
    "            ]\n",
    "\n",
    "    # to have empty row on top and be well aligned with other dfs\n",
    "    for i in range(len(just_concat)):\n",
    "        just_concat[i] = insert_row_above(\n",
    "            just_concat[i],\n",
    "            [\"hyperparam\"] * len(just_concat[i].columns)\n",
    "        )\n",
    "\n",
    "    dfs_to_concat = just_concat + dfs_to_concat\n",
    "    if insert_empty_cols:\n",
    "        dfs_with_inserted = []\n",
    "        for i, df in enumerate(dfs_to_concat):\n",
    "            dfs_with_inserted.append(df)\n",
    "            if i + 1 != len(dfs_to_concat):\n",
    "                dfs_with_inserted.append(pd.Series(dtype='int'))\n",
    "        dfs_to_concat = dfs_with_inserted\n",
    "\n",
    "    res_df = pd.concat(dfs_to_concat, axis=axis)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def format_number(pm_str):\n",
    "    if pm_str is None:\n",
    "        return pm_str\n",
    "    number = pm_str.split('+-')[0]\n",
    "    return abs(float(number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD genearalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(PICKLES_PATH, \"deit3b_ood_gen.pkl\")\n",
    "# /home/oh/arubinstein17/github/diverse-universe-public/result_pickles/deit3b_ood_gen.pkl\n",
    "\n",
    "\n",
    "\n",
    "df = get_long_table(\n",
    "    [\n",
    "        _path,\n",
    "    ],\n",
    "    [\n",
    "        (\"submodel_0\", 100),\n",
    "        (\"submodel_1\", 100),\n",
    "        (\"submodel_2\", 100),\n",
    "        (\"submodel_3\", 100),\n",
    "        (\"submodel_4\", 100),\n",
    "        (\"best_single_model\", 100),\n",
    "        (\"mean_single_model\", 100),\n",
    "        (\"ensemble\", 100),\n",
    "        (\"soup\", 100),\n",
    "        \"div_different_preds\",\n",
    "        \"div_continous_unique\",\n",
    "        \"var\"\n",
    "    ],\n",
    "    axis=1,\n",
    "    row_names=None,\n",
    "    col_names=[\n",
    "        \"in_val\",\n",
    "        \"imagenet_a\",\n",
    "        \"imagenet_r\",\n",
    "        \"C-1\",\n",
    "        \"C-5\",\n",
    "        \"iNaturalist\",\n",
    "        \"OpenImages\"\n",
    "    ],\n",
    "    format_func=format_number,\n",
    "    merge_map={\n",
    "        \"C-1\": [corruption + \"_1\" for corruption in ALL_CORRUPTION_NAMES],\n",
    "        \"C-5\": [corruption + \"_5\" for corruption in ALL_CORRUPTION_NAMES],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pkl_path = os.path.join(PICKLES_PATH, \"deit3b_ood_det.pkl\")\n",
    "# all_corruption_names = list(IN_C_DATALOADERS_NAMES.values())\n",
    "\n",
    "df = get_long_table(\n",
    "    [\n",
    "        _pkl_path,\n",
    "    ],\n",
    "    [\n",
    "        (\"ensemble\", 1),\n",
    "        (\"submodel_0\", 1),\n",
    "        (\"divs\", 1),\n",
    "        (\"cont_unique\", 1),\n",
    "    ],\n",
    "    axis=1,\n",
    "    row_names=None,\n",
    "    col_names=[\n",
    "    \"C-1\",\n",
    "    \"C-5\",\n",
    "    \"iNaturalist\",\n",
    "    \"OpenImages\"\n",
    "    ],\n",
    "    format_func=format_number,\n",
    "    merge_map={\n",
    "        \"C-1\": [corruption + \"_1\" for corruption in ALL_CORRUPTION_NAMES],\n",
    "        \"C-5\": [corruption + \"_5\" for corruption in ALL_CORRUPTION_NAMES]\n",
    "    },\n",
    "    group_by_columns=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>C-1</th>\n",
       "      <th>C-1</th>\n",
       "      <th>C-1</th>\n",
       "      <th>C-1</th>\n",
       "      <th>1</th>\n",
       "      <th>C-5</th>\n",
       "      <th>C-5</th>\n",
       "      <th>C-5</th>\n",
       "      <th>C-5</th>\n",
       "      <th>2</th>\n",
       "      <th>iNaturalist</th>\n",
       "      <th>iNaturalist</th>\n",
       "      <th>iNaturalist</th>\n",
       "      <th>iNaturalist</th>\n",
       "      <th>3</th>\n",
       "      <th>OpenImages</th>\n",
       "      <th>OpenImages</th>\n",
       "      <th>OpenImages</th>\n",
       "      <th>OpenImages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(ensemble, 1)</td>\n",
       "      <td>(submodel_0, 1)</td>\n",
       "      <td>(divs, 1)</td>\n",
       "      <td>(cont_unique, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ensemble, 1)</td>\n",
       "      <td>(submodel_0, 1)</td>\n",
       "      <td>(divs, 1)</td>\n",
       "      <td>(cont_unique, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ensemble, 1)</td>\n",
       "      <td>(submodel_0, 1)</td>\n",
       "      <td>(divs, 1)</td>\n",
       "      <td>(cont_unique, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ensemble, 1)</td>\n",
       "      <td>(submodel_0, 1)</td>\n",
       "      <td>(divs, 1)</td>\n",
       "      <td>(cont_unique, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deit3b_budget_v2_</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585738</td>\n",
       "      <td>0.581696</td>\n",
       "      <td>0.525666</td>\n",
       "      <td>0.596753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822406</td>\n",
       "      <td>0.814783</td>\n",
       "      <td>0.626635</td>\n",
       "      <td>0.799279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954604</td>\n",
       "      <td>0.946649</td>\n",
       "      <td>0.676421</td>\n",
       "      <td>0.835179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904268</td>\n",
       "      <td>0.896585</td>\n",
       "      <td>0.63528</td>\n",
       "      <td>0.789326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0            C-1              C-1        C-1  \\\n",
       "0                 NaN  (ensemble, 1)  (submodel_0, 1)  (divs, 1)   \n",
       "deit3b_budget_v2_ NaN       0.585738         0.581696   0.525666   \n",
       "\n",
       "                                C-1   1            C-5              C-5  \\\n",
       "0                  (cont_unique, 1) NaN  (ensemble, 1)  (submodel_0, 1)   \n",
       "deit3b_budget_v2_          0.596753 NaN       0.822406         0.814783   \n",
       "\n",
       "                         C-5               C-5   2    iNaturalist  \\\n",
       "0                  (divs, 1)  (cont_unique, 1) NaN  (ensemble, 1)   \n",
       "deit3b_budget_v2_   0.626635          0.799279 NaN       0.954604   \n",
       "\n",
       "                       iNaturalist iNaturalist       iNaturalist   3  \\\n",
       "0                  (submodel_0, 1)   (divs, 1)  (cont_unique, 1) NaN   \n",
       "deit3b_budget_v2_         0.946649    0.676421          0.835179 NaN   \n",
       "\n",
       "                      OpenImages       OpenImages OpenImages        OpenImages  \n",
       "0                  (ensemble, 1)  (submodel_0, 1)  (divs, 1)  (cont_unique, 1)  \n",
       "deit3b_budget_v2_       0.904268         0.896585    0.63528          0.789326  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = os.path.join(get_project_root_path(), \"tmp\")\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "df.to_csv(os.path.join(tmp_folder, \"tmp_csv.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
