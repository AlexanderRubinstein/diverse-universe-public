cache_path: ./cache
checkpoint_symlink: "./models/symlinked/50_models.pkl"
data:
    dataset:
        from_h5:
            eval_splits:
                - val
            keys_order:
                - embed
                - label
            max_chunk: 1281167
            num_classes: 1000
            path:
                train: ./data/datasets/cached/in_train_deit3b_-1_4_epochs.hdf5
                val: ./data/datasets/cached/in_val_deit3b_-1.hdf5
            total_samples:
                train: 5124668
        type: from_h5
        use_train_for_eval: false

    num_data_readers: 0
    unlabeled_dataset: null

model:
    redneck_ensemble:
        base_estimator:
            resnet50:
                n_channels: 3
                n_classes: 2
                pretrained: true
            separation_config:
                block_id: -1
                separate: classifier
            torch_load:
                model_name: deit3_21k
                path: null
            type: torch_load
        keep_inactive_on_cpu: true
        n_models: 50
        random_select: 2
    type: redneck_ensemble
params:
    eval:
        batch_size: 32
        eval_only_last_epoch: false
    metric:
        accuracy_top_k:
            top_k: 1
        type: accuracy_top_k
    random_seed: 42
    setup: default
    to_eval: true
    to_profile: false
    to_train: true
    train:
        batch_size: 16
        criterion:
            divdis:
                disagree_after_epoch: 0
                disagree_below_threshold: null
                lambda: 0.5
                loss_type: a2d
                manual_lambda: 0.0002
                modifier: budget
                task_loss:
                    type: xce
                use_always_labeled: false
            type: divdis
        freeze_model_on_first_epoch: true
        n_epochs: 11
        optimizer:
            adam:
                weight_decay: 0.9
            nan_checking: true
            sgd:
                momentum: 0.9
                weight_decay: 0.0001
            start_lr: 0.001
            type: sgd
        reset_epochs: true
    use_gpu: true
# patch:
#     diversity_lambda: 0.5
statistics:
    batchwise: false
    keep_modelwise: false
    use_tb: false
    use_wandb: false
    wandb:
        netrc_path: ~/.netrc
        stats:
            input: false
            logits: false
            loss: true
            metrics: true
            prediction: false
            target: false
        wandb_init_kwargs:
            tags:
                - budget_train
use_hardcoded_config: false
