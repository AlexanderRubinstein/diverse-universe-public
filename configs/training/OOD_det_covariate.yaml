cache_path: ./cache
checkpoint_symlink: "./models/symlinked/ood_det_cov.pkl"
data:
  dataset:
    from_h5:
      eval_splits:
      - val
      keys_order:
      - embed
      - label
      max_chunk: 1281167
      num_classes: 1000
      path:
        train: ./data/datasets/cached/in_train_deit3b_-1_4_epochs.hdf5
        val: ./data/datasets/cached/in_val_deit3b_-1.hdf5
      total_samples:
        train: 5124668
    type: from_h5
    use_train_for_eval: false
  num_data_readers: 0

model:
  redneck_ensemble:
    base_estimator:
      separation_config:
        block_id: -1
        separate: classifier
      torch_load:
        model_name: deit3_21k
        path: null
      type: torch_load
    keep_inactive_on_cpu: false
    n_models: 5
    random_select: 2
  type: redneck_ensemble
params:
  eval:
    batch_size: 32
    eval_only_last_epoch: false
  metric:
    accuracy_top_k:
      top_k: 1
    type: accuracy_top_k
  random_seed: 42
  setup: default
  to_eval: true
  to_profile: false
  to_train: true
  train:
    batch_size: 32
    criterion:
      divdis:
        disagree_after_epoch: 0
        disagree_below_threshold: null
        lambda: null
        loss_type: a2d
        manual_lambda: 5
        modifier: budget
        task_loss:
          type: xce
        use_always_labeled: true
      smoothing_eps: 0.5
      type: divdis
    freeze_model_on_first_epoch: true
    n_epochs: 11
    optimizer:
      adam:
        weight_decay: 0.9
      adamW:
        weight_decay: 0.1
      lr_scheduler:
        from_class-cosine_scheduler:
          class: torch.optim.lr_scheduler.CosineAnnealingLR
          kwargs:
            T_max: 15
        type: from_class-cosine_scheduler
      sgd:
        momentum: 0.0
        weight_decay: 0.0
      start_lr: 0.001
      type: adamW
    reset_epochs: true
  use_gpu: true
patch:
  diversity_lambda: 0.5
statistics:
  batchwise: false
  keep_modelwise: false
  use_tb: false
  use_wandb: false
  # wandb:
  #   netrc_path: ~/.netrc
  #   stats:
  #     input: false
  #     logits: false
  #     loss: true
  #     metrics: true
  #     prediction: false
  #     target: false
  #   wandb_init_kwargs:
  #     tags:
  #     - budget_loss_stronger_hp
use_hardcoded_config: false
